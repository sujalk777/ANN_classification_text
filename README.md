# ANN-Hindi-Character-Classification-in-C-from-scratch
A neural network built from scratch in C++ to classify handwritten Hindi characters using a custom dataset.
# ğŸ§  Hindi Character Classification using ANN from Scratch in C++

This project implements a **4-layer artificial neural network (ANN)** completely from scratch in **C++** to classify **handwritten Hindi characters**. From collecting the dataset to deriving backpropagation gradients by hand, this project is focused on understanding the inner mechanics of neural networks â€” not just using them.

---

## ğŸ“Œ Project Overview

- ğŸ–‹ï¸ Created a custom dataset of **handwritten Hindi characters**
- ğŸ§® Implemented a **fully connected ANN** with:
  - Input Layer: 225 (15Ã—15 grayscale image)
  - Hidden Layers: 2 Ã— 15 neurons
  - Output Layer: 10 classes (one-hot)
- ğŸ’» Entire model written in **C++**, without any ML frameworks
- ğŸ” Implemented forward propagation, sigmoid/leaky ReLU, softmax, MSE and cross-entropy loss
- ğŸ“‰ Used **gradient descent with momentum** and performed extensive hyperparameter tuning

---

## ğŸ“ ANN Architecture

<p align="center">
  <img src="images/Screenshot 2025-05-04 202549.png" width="600" alt="Architecture Diagram">
</p>

---

## ğŸ§® Training & Optimization Highlights

- Initially trained with **MSE loss** + **sigmoid**, later switched to:
  - **Cross-entropy loss** + **softmax**
  - **Leaky ReLU** to overcome vanishing gradients
- Manually derived backpropagation gradients for all layers
- Implemented **momentum**-based gradient updates
- Explored hyperparameters: learning rate, momentum, epochs

---

## ğŸ“Š Results

### ğŸ” Epochs vs Training Error and Testing Accuracy

<p align="center">
  <img src="images/Screenshot 2025-05-01 000352.png" width="600" alt="Epoch vs Error/Accuracy">
</p>

---

### ğŸ“ˆ 3D Plot: Epochs vs Learning Rate vs Error/Accuracy

<p align="center">
  <img src="images/Screenshot 2025-05-01 000411.png" width="500" alt="3D Hyperparameter Plot">
</p>

---

### ğŸ“‰ Confusion Matrix on Validation Set

<p align="center">
  <img src="images/Screenshot 2025-05-05 121605.png" width="300" alt="Confusion Matrix">
</p>

- **Validation Accuracy:** `60.07%`
- Errors mostly occurred in visually similar characters
- Demonstrates meaningful pattern learning

---

## ğŸ“‚ Folder Structure

ğŸ“ training/
â”œâ”€â”€ main_training.cpp
â””â”€â”€ weights.bin # Binary file after training

ğŸ“ testing/
â”œâ”€â”€ main_testing.cpp
â””â”€â”€ weights.bin # Used for inference

ğŸ“ notes/
â””â”€â”€ handwritten_derivations.png

ğŸ“ results/
â”œâ”€â”€ loss_accuracy_plot.png
â”œâ”€â”€ 3d_plot.png
â””â”€â”€ confusion_matrix.png

---

## ğŸ’¡ Key Learnings

- Backpropagation is easier to understand once you derive and code it yourself.
- MSE isn't suited for multi-class classification â€” switching to cross-entropy was essential.
- Sigmoid is vulnerable to vanishing gradients; leaky ReLU solved it for deeper networks.
- Momentum accelerated convergence and reduced the noise in weight updates.
- Generalization is bounded by data quantity and quality; this project hit ~60% validation accuracy with ~3500 images.

---

## ğŸ“½ï¸ Demo & Notes

- ğŸ¥ *A screen recording video (training + testing)* will be pinned on LinkedIn & is also available in the result folder.
- âœï¸ *Handwritten derivations and architecture diagrams* are available in the `notes/` folder.

---

## ğŸ“Œ TODO / Future Work

- Expand dataset to include more characters
- Try regularization (dropout/L2) & will try to build a cnn from scratch
- Port the model to Python/CUDA for speedup
- Compare with a PyTorch equivalent implementation

---

## ğŸ™‹â€â™‚ï¸ Author

**Sarthak patial**  
`Computer Science Undergraduate`  
xarthak@proton.me , connect me over linkeden

